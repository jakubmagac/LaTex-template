% !TEX root = ../thesis.tex

\chapter{Strojové učenie}
Strojové učenie je veda zaoberajúca sa počítačovými algoritmami, ktoré sa dokážu zlepšovať automaticky, pomocou skúsenosti a pomocou použití dát [5]. Strojové učenie je použitie algoritmu, ktorý sa snaží nájsť vzory v dátach a potom použitia takto naučeného algoritmu na podobných dátach s cieľom vytvoriť predikciu pre nové dáta. Alogrimy preberajú postupy zo štatistiky, príkladom môže byť aj už spomínaná lineárna regresia. 

\section{Typy strojového učenia}
Strojové učnie možeme rozdeliť na tri časti: učenie s učiteľom, učenie bez učiteľa a učenie posilňovaním.

\subsection{Učenie s učiteľom}
Forma strojového učenia, pri ktorom majú naše dáta aj určené do ktorej triedy, ktorú chceme predikovať patria. Naše namerané X hodnoty najú svoje y. Napríklad klasický prípad môže byť rozpoznávanie číslic. Majme sadu obrázkov s ručne písanými číslicami a každá vzorka má svoju triedu do ktorej patrí (jednička, dvojka...). Cieľom nášho modelu, bude predikcia o aké číslo ide.

\subsection{Učenie bez učiteľa}
Prípad kedy naše dáta nemajú určenú triedu, ktorú potrebujeme predikovať. Algoritmus musí najsť triedy sám. Príkladom takéhoto učnia je napríklad algorimus k-najbližich susedov, kde algoritmus zhlukuje klastre pomocou vzoriek, ktoré sa nachádzajú blizko pri sebe. Využitie takéhoto algorimtu môže byť pri modely, ktorý sa bude snažiť odhadovať o aký tovar by mal záujem návštevník obchodu, na základe jeho predošlých nákupov a prezretých tovarov.

\subsection{Učnie s posilňovaním}
V prípade učnia s posilňovaním je učenie vykonávané formou spätnej väzby, kde v prípade správnej predikcie je algoritmus odmenený a v prípade nesprávnej potrestaný. Príkladom môže byť autonómne vozidlo, ktoré sa snažíme naučiť jazdiť v súlade s dopravnými predpismi.

\subsection{Dáta}
Pre každú formu strojového učenia potrebujeme nejaké dáta, na ktorých sa bude náš model učiť a testovať. Dáta možu byť rôznych formátov od nahrávok zvuku, obrázkov, cez písaný text, avšak najčastejšie ide o tabuľy pozostávajúce z uskutočnených meraní - vzoriek. Každá vzorka má svoje atribúty a v prípade učenia s učiteľom aj svoju triedu. 

\section{Proces strojového učenia}
Proces strojového učenia pozostáva z viacero časti. Prvou časťou je zber dát. V praxi častokrát dostane Machine learning engineer už pripravené dáta, ak firma zbierala dáta od zákazníkov alebo dostala výsledky prieskumu. Poprípade si vieme dáta zozbierať aj sami, napríklad vytvorením web scrappera, ktorý nám zozbiera dáta z webu.

Ďalšou časťou procesu je predspracovanie dát. Zo zozbieraných dát musíme vybrať dáta ktoré sú pre nás relevantné. Musíme sa usistiť že nemáme nejaké prázdne hodnoty, v takom prípade musíme buď zmazať celé jedno merianie, alebo tam imputovať priemerné hodnoty, Musíme premeniť znakové hodnoty na číselné, pričom musíme zohľadniť rozdiely medzi ordinálnymi a nominálnymi atribútmi. Ak máme veľký nepomer vo veľkosti číselných atribúov, musíme aplikovať škálovanie a/alebo normalizáciu. A v neposlednom rade musíme rozdeliť naše dáta na trénovacie a testovacie. Nesmie nastať situácia aby sme použili časť testovacích dát na trénovanie a naopak.

Keď máme spravené predspracovanie dát, môžeme sa pustiť do výberu modelu. Je ideálne si vyskúšať viacero možných algoritmov a zároveň aj parametrov. Pomocou cross-validácie zitíme ktorý model a jeho nastavenia budú najviac vyhovovať nášmu riešeniu. 

Keď máme náš model natrénvaný, môžeme pristúpiť k ďalšiemu kroku, čo je evaluácia modelu. Necháme zbehnuť náš model na testovacích dátach a necháme ho predikovať hodnoty. 

Ako posledná časť procesu je nasadenie modelu (deploy) do aplikácie. Táto časť procesu nie je súčasťou zadania, avšak ak by sme robili model do praxe, tak by sme napríklad chceli náš model na predikciu kníh, ktoré by sa mohli zákazníkovi páčiť, nasadiť do aplikácie knihkupectva.

\section{Regresná analýza}
Problémy, storjového učenia vieme rozdeliť na štyri základné podkategórie. Klasifikácia, klastrovanie, regresná analýza a redukcia dimenzionality. Pre potreby nášho problému budeme používať regresiu. Regresia je závislosť priemernej hodnoty nejakej náhodnej premennej na inej alebo viacero iných premenných. [1]. Regresné modely používame pre predikciu premenných na súvislej mierke.  Preto pri implementácii modelu využijeme regresné algoritmy z knižnice sickit-learn. Pri výbere vhodného esitimátora si môžeme pomôcť grafom z dokumenácie scikit-learn. [2]. V prvej časti práce sa pozrieme na teoretickú časť týchto algoritmov a potom v druhej časti sa pozrieme na porovnania presnosti modelov daných algoritmov.

\subsection{Lineárna regresia}

Algoritmus vyjadruje vzťah medzi premennou x a výslednou premennou y. Grafom takejto funkcie je lineárne rastúca/ klesajúca priamka. Pre výpočet vzťahu použijeme vzorec:
\[ y = w_{0} + w_{1} x \]

čo predstavuje jednoduchú lineárnu regresiu, Ak by sme mali viacero príznakov vo vzorke, šlo by o viacnásobnú lineárnu regresiu a pre jej výpočet by sme použili súčet všetkých príznakov.
\[ y = w_{0} x_{0} + w_{1} x_{1} ... w_{m} x_{m} \]

\subsection{Ridge regresia}
Tiež známa ako hrebeňová regresia. Používa sa na dáta, ktoré tŕpia multikolinearitou. Multikolinearita nastáva, ak máme v matici príznakov (X) determinant rovný alebo velmi blízky 0. Algorimus využíva lineárnu regresiu s regularizáciou L2. Komplexný parameter $\lambda$ $\geq$ 0 kontroluje množstvo zmenšenia: čím je väčšia hodnota $\lambda$, tým väčšia je hodnota zmenšenia a tým sa koeficienty stanú robustnejšie pre kolinearitu [3]. L2 penalizácia je rovná druhej mocnine veľkosti koeficientov.
\[L2: \lambda ||w || _{2}^{2} = \lambda \sum_{j=1}^{m} {w_{j}}^{2} \]

\subsection{LASSO}
Je skratka pre Least Absolute Shrinkage and Selection Operator. Vykonáva L1 reguláciu - pripočítavá penalizáciu rovnú absolútnej hodnote veľkosti koeficientov. Dokáže odhadovať riedke koeficienty. Je užitočný v niektorých kontextich vzhľadom na jeho tendenciu uprednostnovať riešenia s menším počtom nenulových koeficientov, čím sa efektívne znižuje počet vlastností, na ktorých je dané riešenie závislé. [3]

\[L1: \lambda ||w || _{1} = \lambda \sum_{j=1}^{m}\left | w_{j} \right |\]

\subsection{Elastic Net}
Je algoritmus, ktorý využíva kombináciu LASSO a Ridge regresie, L1 a L2 regularizáciu. Elasic Net vylepšuje LASSO limitácie. Vďaka Ridge regresii, Elastic Net estimator dokáže spracovať korelácie, medzi predikatormi lepšie ako LASSO a vďaka L1 regularizácii, získame riedkosť. [7]

\[J(w)_{ElasticNet} = \sum_{i=1}^{n}(y^{(i)} - \hat{y}^{(i)})^{2} + \lambda _{1}\sum_{j=1}^{m} {w_{j}}^{2}+ \lambda_{2} \sum_{j=1}^{m}\left | w_{j} \right | \]

\subsection{DecisionTreeRegressor}
\subsection{RandomForestRegressor}
\subsection{Epsilon-Support Vector Regression}

\subsection{SGDRegressor}
Stochastic Gradient Descent. Sklon straty sa odhaduje každou vzorkou a model sa upravuje zároveň s klesajúcou silou rozvrhu (learning rate) [8]. SGDRegressor podporuje rôzne funkcie strát a penalizácii. 